{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from __future__ import print_function\r\n",
    "import cv2 as cv\r\n",
    "import numpy as np\r\n",
    "import glob\r\n",
    "import os\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading Database folder using glob and calculating kp and dc \r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(\"Please choose detector form SIFT AND ORB\")\r\n",
    "detector_name = input()\r\n",
    "print(\"Choosed Detector:\",detector_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please choose detector form SIFT AND ORB\n",
      "Choosed Detector: ORB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if detector_name == \"SIFT\":\r\n",
    "    detector = cv.SIFT_create()\r\n",
    "elif detector_name == \"ORB\":\r\n",
    "    detector = cv.ORB_create()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "images_data = []\r\n",
    "for img in glob.glob(\"C:/Users/piyus/OneDrive/Documents/Office/24Sep/storing_keypoints_descriptors_yml/database/*.jpg\"):\r\n",
    "        n = cv.imread(img, cv.IMREAD_GRAYSCALE)\r\n",
    "        kp, dc = detector.detectAndCompute(n, None)\r\n",
    "        keypoints = []\r\n",
    "        for p in kp:\r\n",
    "            temp = (p.pt, p.size, p.angle, p.response, p.octave, p.class_id)\r\n",
    "            keypoints.append(temp)\r\n",
    "\r\n",
    "        img_info={\r\n",
    "            \"image_name\" : os.path.basename(img),\r\n",
    "            \"image_kp\"   : keypoints,\r\n",
    "            \"image_dp\"   : dc\r\n",
    "        }\r\n",
    "        images_data.append(img_info)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------------------------------------------  # DATABASE LOADED # ----------------------------------------------------------------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving Database in pickle\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "with open(\"sources_data.pickle\", mode=\"wb\") as f:\r\n",
    "    pickle.dump(images_data, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using stored database for finding "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading query image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Load Query image\r\n",
    "Query_img = cv.imread(\"Query.jpg \")\r\n",
    "Query_keypoint, Query_descriptor = detector.detectAndCompute(Query_img, None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting data from stored file and converting keypoints to objects\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def get_sources():\r\n",
    "    \"\"\"Get source's features from file\r\n",
    "        Returns:\r\n",
    "            sources(list): source's keypoints, descriptors,and img\r\n",
    "        \"\"\"\r\n",
    "    #Get feature point information from a file\r\n",
    "\r\n",
    "    with open(\"sources_data.pickle\", mode=\"rb\") as f:\r\n",
    "        images_data_loaded = pickle.load(f)\r\n",
    "    for items in images_data_loaded:\r\n",
    "        \r\n",
    "        #Restore keypoints to original structure\r\n",
    "\r\n",
    "        keypoints = []\r\n",
    "        for p in items[\"image_kp\"]:\r\n",
    "            temp = cv.KeyPoint(\r\n",
    "                x=p[0][0],\r\n",
    "                y=p[0][1],\r\n",
    "                size=p[1],\r\n",
    "                angle=p[2],\r\n",
    "                response=p[3],\r\n",
    "                octave=p[4],\r\n",
    "                class_id=p[5],\r\n",
    "            )\r\n",
    "            keypoints.append(temp)\r\n",
    "        items[\"image_kp\"] = keypoints\r\n",
    "\r\n",
    "    return images_data_loaded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "images_data_loaded = get_sources()\r\n",
    "matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Matching\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "for n in images_data_loaded:\r\n",
    "    knn_matches = matcher.knnMatch(n[\"image_dp\"], Query_descriptor, k=2)\r\n",
    "    #Thin out data\r\n",
    "    ratio = 0.5\r\n",
    "    matched_keypoints = []\r\n",
    "    for m, n in knn_matches:\r\n",
    "        if m.distance < ratio * n.distance:\r\n",
    "            matched_keypoints.append([m])\r\n",
    "\r\n",
    "    #Output the result image when there are more good than any threshold\r\n",
    "    if len(matched_keypoints) > 20:\r\n",
    "        print(\"img found\")\r\n",
    "            "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-1i5nllza\\opencv\\modules\\flann\\src\\miniflann.cpp:336: error: (-210:Unsupported format or combination of formats) in function 'cv::flann::buildIndex_'\n> type=0\n> ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26300/100643484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages_data_loaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image_dp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuery_descriptor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#Thin out data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmatched_keypoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-1i5nllza\\opencv\\modules\\flann\\src\\miniflann.cpp:336: error: (-210:Unsupported format or combination of formats) in function 'cv::flann::buildIndex_'\n> type=0\n> "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('flann': conda)"
  },
  "interpreter": {
   "hash": "0f1faf62f511cbdfd9b3b35d905ea8e57a0b3d87bc987c8ce708198a45429283"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}